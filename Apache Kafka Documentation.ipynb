{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d70dae2-d285-41f5-9384-ba6d4c3e5a51",
   "metadata": {},
   "source": [
    "Definition: Zookeeper is used for distributed coordination and management of Kafka brokers. It helps in managing broker metadata and leader election."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6f4d499-655a-4ba9-8835-88010d29b979",
   "metadata": {},
   "source": [
    "#Starting Zookeeper\n",
    "Zookeeper must be running before you start Kafka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d58e8c-b172-4195-96a8-19780db0d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "brew services start zookeeper\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba8925bd-e7ae-4eaa-a030-2f28f2e55968",
   "metadata": {},
   "source": [
    "#Starting Kafka\n",
    "After Zookeeper is up and running, start Kafka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063cb7d0-5113-4664-8b87-927676760f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "brew services start kafka\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d36bda8-3d3b-4623-a076-e2743f209f54",
   "metadata": {},
   "source": [
    "##Creating a Topic\n",
    "--partitions: Number of partitions for the topic.\n",
    "--replication-factor: Number of replicas for each partition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033b618-058f-4dde-8d46-bb24dc4929e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka-topics --create --topic test_topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b80379f5-577b-4b75-80de-4dea46462f90",
   "metadata": {},
   "source": [
    "Producing Messages\n",
    "To produce messages to a topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641da9e0-5457-4d8e-af03-4c1cebe243e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka-console-producer --topic test_topic --bootstrap-server localhost:9092\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2a6a220-c8e7-43ad-bfc6-0842db8cba1a",
   "metadata": {},
   "source": [
    "Consuming Messages\n",
    "To consume messages from a topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593876d-d7c7-4244-a26a-3778a674a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka-console-consumer --topic test_topic --bootstrap-server localhost:9092 --from-beginning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae641c0-6296-490c-919f-e963ee7ded11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "# Configuration for the Kafka producer\n",
    "conf = {\n",
    "    'bootstrap.servers': ''}\n",
    "\n",
    "# Create a Producer instance\n",
    "producer = Producer(conf)\n",
    "\n",
    "# Define a callback function to be called upon message delivery\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered to {msg.topic()} [{msg.partition()}]\")\n",
    "\n",
    "def send_message(topic, message):\n",
    "    try:\n",
    "        # Produce a message to the specified topic\n",
    "        producer.produce(topic, message, callback=delivery_report)\n",
    "        # Wait up to 1 second for events to be delivered\n",
    "        producer.flush()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e2db8-850b-4c53-91ef-a23d44515c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'sample_topic'\n",
    "send_message(topic, 'message to consumer ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5ca71-7656-490d-8c20-2cbfdd0049c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d848dca-0b82-462d-a20b-52da6d64eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "# Configuration for the Kafka consumer\n",
    "conf = {\n",
    "    'bootstrap.servers': '',  # Address of the Kafka cluster\n",
    "    'group.id': 'my-consumer-group',         # Consumer group ID\n",
    "    'auto.offset.reset': 'earliest'          # Start reading from the earliest message\n",
    "}\n",
    "\n",
    "# Create a Consumer instance\n",
    "consumer = Consumer(conf)\n",
    "\n",
    "# Subscribe to the topic\n",
    "topic = 'sample_topic'\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "print(f\"Consuming messages from topic '{topic}'...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Poll for new messages\n",
    "        msg = consumer.poll(timeout=1.0)  # Adjust timeout as needed\n",
    "\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                # End of partition\n",
    "                continue\n",
    "            elif msg.error():\n",
    "                # Log or handle other errors\n",
    "                print(f\"Error: {msg.error()}\")\n",
    "                break\n",
    "\n",
    "        # Print the message\n",
    "        print(f\"Received message: {msg.value().decode('utf-8')}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Handle the interrupt gracefully\n",
    "    print(\"Interrupted by user\")\n",
    "\n",
    "finally:\n",
    "    # Close the consumer to clean up resources\n",
    "    consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d50bf-33ed-4116-9836-aa042873b11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538a394-cca8-44ea-a79e-1bf1d7d5e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Initialize SparkSession with Kafka package\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStreaming\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define Kafka parameters\n",
    "kafka_bootstrap_servers = ''\n",
    "kafka_topic = 'sample_topic'\n",
    "\n",
    "# Define a function to start the stream and handle termination\n",
    "def start_streaming():\n",
    "    # Read data from Kafka\n",
    "    df = spark.readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "        .option(\"subscribe\", kafka_topic) \\\n",
    "        .load()\n",
    "\n",
    "    # Convert Kafka data into DataFrame\n",
    "    df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "    # Define a file path to save the final data\n",
    "    final_output_path = \"/path/to/final_output\"  # Adjust path as needed\n",
    "\n",
    "    # Write Stream to a file\n",
    "    query = df.writeStream \\\n",
    "        .format(\"console\") \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .start()\n",
    "\n",
    "# Await termination\n",
    "query.awaitTermination()\n",
    "\n",
    "    # Return the query so it can be managed or stopped later\n",
    "    return query\n",
    "\n",
    "# Start streaming and get the query object\n",
    "query = start_streaming()\n",
    "\n",
    "# Check the status of the query\n",
    "query.status\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
